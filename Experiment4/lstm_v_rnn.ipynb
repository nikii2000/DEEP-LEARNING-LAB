{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38a35d4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T13:32:09.732909Z",
     "iopub.status.busy": "2025-03-20T13:32:09.732673Z",
     "iopub.status.idle": "2025-03-20T13:32:09.736825Z",
     "shell.execute_reply": "2025-03-20T13:32:09.736080Z"
    },
    "papermill": {
     "duration": 0.009389,
     "end_time": "2025-03-20T13:32:09.737962",
     "exception": false,
     "start_time": "2025-03-20T13:32:09.728573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Text Generation Using RNN and LSTM for 100 Poem Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ce5153b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-20T13:32:09.744435Z",
     "iopub.status.busy": "2025-03-20T13:32:09.744209Z",
     "iopub.status.idle": "2025-03-20T13:32:12.691529Z",
     "shell.execute_reply": "2025-03-20T13:32:12.690846Z"
    },
    "papermill": {
     "duration": 2.952079,
     "end_time": "2025-03-20T13:32:12.693029",
     "exception": false,
     "start_time": "2025-03-20T13:32:09.740950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "226845fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T13:32:12.701566Z",
     "iopub.status.busy": "2025-03-20T13:32:12.701203Z",
     "iopub.status.idle": "2025-03-20T13:32:12.723287Z",
     "shell.execute_reply": "2025-03-20T13:32:12.722497Z"
    },
    "papermill": {
     "duration": 0.027058,
     "end_time": "2025-03-20T13:32:12.724508",
     "exception": false,
     "start_time": "2025-03-20T13:32:12.697450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "text = \"\"\n",
    "with open(\"/kaggle/input/poems-dataset/poems-100.csv\", \"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        text += \" \".join(row) + \" \"                          # Combine All Lines into a Single Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43391467",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T13:32:12.730823Z",
     "iopub.status.busy": "2025-03-20T13:32:12.730587Z",
     "iopub.status.idle": "2025-03-20T13:32:12.735930Z",
     "shell.execute_reply": "2025-03-20T13:32:12.735131Z"
    },
    "papermill": {
     "duration": 0.009889,
     "end_time": "2025-03-20T13:32:12.737209",
     "exception": false,
     "start_time": "2025-03-20T13:32:12.727320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize the Text into Words\n",
    "tokens = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27922554",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T13:32:12.743639Z",
     "iopub.status.busy": "2025-03-20T13:32:12.743433Z",
     "iopub.status.idle": "2025-03-20T13:32:12.752099Z",
     "shell.execute_reply": "2025-03-20T13:32:12.751565Z"
    },
    "papermill": {
     "duration": 0.013126,
     "end_time": "2025-03-20T13:32:12.753250",
     "exception": false,
     "start_time": "2025-03-20T13:32:12.740124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a Dictionary to Map Words to Indices\n",
    "word_to_idx = {}\n",
    "idx_to_word = {}\n",
    "vocab_size = 0\n",
    "\n",
    "for word in tokens:\n",
    "    if word not in word_to_idx:\n",
    "        word_to_idx[word] = vocab_size\n",
    "        idx_to_word[vocab_size] = word\n",
    "        vocab_size += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68cc011d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T13:32:12.759605Z",
     "iopub.status.busy": "2025-03-20T13:32:12.759384Z",
     "iopub.status.idle": "2025-03-20T13:32:12.763966Z",
     "shell.execute_reply": "2025-03-20T13:32:12.763333Z"
    },
    "papermill": {
     "duration": 0.008949,
     "end_time": "2025-03-20T13:32:12.765032",
     "exception": false,
     "start_time": "2025-03-20T13:32:12.756083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert Tokens to Indices\n",
    "token_indices = [word_to_idx[word] for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a5a8eef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T13:32:12.771420Z",
     "iopub.status.busy": "2025-03-20T13:32:12.771197Z",
     "iopub.status.idle": "2025-03-20T13:32:12.775207Z",
     "shell.execute_reply": "2025-03-20T13:32:12.774392Z"
    },
    "papermill": {
     "duration": 0.008412,
     "end_time": "2025-03-20T13:32:12.776387",
     "exception": false,
     "start_time": "2025-03-20T13:32:12.767975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 7460\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocabulary Size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3caed8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T13:32:12.782979Z",
     "iopub.status.busy": "2025-03-20T13:32:12.782761Z",
     "iopub.status.idle": "2025-03-20T13:32:12.878279Z",
     "shell.execute_reply": "2025-03-20T13:32:12.877432Z"
    },
    "papermill": {
     "duration": 0.100337,
     "end_time": "2025-03-20T13:32:12.879715",
     "exception": false,
     "start_time": "2025-03-20T13:32:12.779378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Sequences and Targets\n",
    "seq_length = 10\n",
    "sequences = []\n",
    "targets = []\n",
    "\n",
    "for i in range(len(token_indices) - seq_length):\n",
    "    seq = token_indices[i:i + seq_length]\n",
    "    target = token_indices[i + seq_length]\n",
    "    sequences.append(seq)\n",
    "    targets.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98a351c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T13:32:12.886980Z",
     "iopub.status.busy": "2025-03-20T13:32:12.886746Z",
     "iopub.status.idle": "2025-03-20T13:32:12.922962Z",
     "shell.execute_reply": "2025-03-20T13:32:12.922155Z"
    },
    "papermill": {
     "duration": 0.041144,
     "end_time": "2025-03-20T13:32:12.924295",
     "exception": false,
     "start_time": "2025-03-20T13:32:12.883151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to PyTorch Tensors\n",
    "sequences = torch.tensor(sequences, dtype = torch.long)\n",
    "targets = torch.tensor(targets, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0509df9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T13:32:12.931197Z",
     "iopub.status.busy": "2025-03-20T13:32:12.930998Z",
     "iopub.status.idle": "2025-03-20T13:32:12.935101Z",
     "shell.execute_reply": "2025-03-20T13:32:12.934483Z"
    },
    "papermill": {
     "duration": 0.008724,
     "end_time": "2025-03-20T13:32:12.936178",
     "exception": false,
     "start_time": "2025-03-20T13:32:12.927454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define One-Hot Encoding for RNN Model\n",
    "class OneHotRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim, output_dim):\n",
    "        super(OneHotRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(vocab_size, hidden_dim, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, _ = self.rnn(x)\n",
    "        out = self.fc(output[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f66644e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T13:32:12.943110Z",
     "iopub.status.busy": "2025-03-20T13:32:12.942914Z",
     "iopub.status.idle": "2025-03-20T13:32:12.947172Z",
     "shell.execute_reply": "2025-03-20T13:32:12.946395Z"
    },
    "papermill": {
     "duration": 0.008936,
     "end_time": "2025-03-20T13:32:12.948302",
     "exception": false,
     "start_time": "2025-03-20T13:32:12.939366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define LSTM Model with Embedding Layer\n",
    "class PoemLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super(PoemLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, _ = self.lstm(embedded)\n",
    "        out = self.fc(output[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "357ec2e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T13:32:12.955139Z",
     "iopub.status.busy": "2025-03-20T13:32:12.954944Z",
     "iopub.status.idle": "2025-03-20T13:32:12.957722Z",
     "shell.execute_reply": "2025-03-20T13:32:12.957142Z"
    },
    "papermill": {
     "duration": 0.007574,
     "end_time": "2025-03-20T13:32:12.958949",
     "exception": false,
     "start_time": "2025-03-20T13:32:12.951375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embed_dim = 100\n",
    "hidden_dim = 128\n",
    "output_dim = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9632a5ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T13:32:12.966182Z",
     "iopub.status.busy": "2025-03-20T13:32:12.965992Z",
     "iopub.status.idle": "2025-03-20T13:32:13.014865Z",
     "shell.execute_reply": "2025-03-20T13:32:13.014286Z"
    },
    "papermill": {
     "duration": 0.05387,
     "end_time": "2025-03-20T13:32:13.016059",
     "exception": false,
     "start_time": "2025-03-20T13:32:12.962189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize Models\n",
    "onehot_model = OneHotRNN(vocab_size, hidden_dim, output_dim)\n",
    "embedding_model = PoemLSTM(vocab_size, embed_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e35a9a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T13:32:13.023028Z",
     "iopub.status.busy": "2025-03-20T13:32:13.022833Z",
     "iopub.status.idle": "2025-03-20T13:32:16.351361Z",
     "shell.execute_reply": "2025-03-20T13:32:16.350684Z"
    },
    "papermill": {
     "duration": 3.333725,
     "end_time": "2025-03-20T13:32:16.352982",
     "exception": false,
     "start_time": "2025-03-20T13:32:13.019257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "onehot_optimizer = optim.Adam(onehot_model.parameters(), lr = 0.001)\n",
    "embedding_optimizer = optim.Adam(embedding_model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4a50089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T13:32:16.360936Z",
     "iopub.status.busy": "2025-03-20T13:32:16.360628Z",
     "iopub.status.idle": "2025-03-20T13:32:16.363774Z",
     "shell.execute_reply": "2025-03-20T13:32:16.363122Z"
    },
    "papermill": {
     "duration": 0.008385,
     "end_time": "2025-03-20T13:32:16.364958",
     "exception": false,
     "start_time": "2025-03-20T13:32:16.356573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss Tracking\n",
    "onehot_losses, embedding_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f792111d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T13:32:16.371997Z",
     "iopub.status.busy": "2025-03-20T13:32:16.371801Z",
     "iopub.status.idle": "2025-03-20T13:32:16.376824Z",
     "shell.execute_reply": "2025-03-20T13:32:16.376207Z"
    },
    "papermill": {
     "duration": 0.00981,
     "end_time": "2025-03-20T13:32:16.377973",
     "exception": false,
     "start_time": "2025-03-20T13:32:16.368163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training Function with Tracking\n",
    "def train_model(model, optimizer, name):\n",
    "    start_time = time.time()\n",
    "    for epoch in range(100):\n",
    "        total_loss = 0\n",
    "        for i in range(0, len(sequences), 32):\n",
    "            batch_seq = sequences[i:i + 32]\n",
    "            batch_target = targets[i:i + 32]\n",
    "\n",
    "            # One-Hot Encoding for OneHotRNN\n",
    "            if name == \"OneHotRNN\":\n",
    "                batch_seq = F.one_hot(batch_seq, num_classes = vocab_size).float()\n",
    "\n",
    "            # Forward Pass\n",
    "            outputs = model(batch_seq)\n",
    "            loss = criterion(outputs, batch_target)\n",
    "\n",
    "            # Backward Pass and Optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / (len(sequences) // 32)\n",
    "        if name == \"OneHotRNN\":\n",
    "            onehot_losses.append(avg_loss)\n",
    "        else:\n",
    "            embedding_losses.append(avg_loss)\n",
    "\n",
    "        print(f\"{name} Epoch [{epoch+1}/100], Avg Loss: {avg_loss:.4f}\")\n",
    "    print(f\"{name} Training Time: {time.time() - start_time:.2f}s\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9311605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T13:32:16.384991Z",
     "iopub.status.busy": "2025-03-20T13:32:16.384798Z",
     "iopub.status.idle": "2025-03-20T13:32:16.389407Z",
     "shell.execute_reply": "2025-03-20T13:32:16.388783Z"
    },
    "papermill": {
     "duration": 0.00948,
     "end_time": "2025-03-20T13:32:16.390665",
     "exception": false,
     "start_time": "2025-03-20T13:32:16.381185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Poem Generation Function\n",
    "def generate_poem(model, seed_text, num_words = 50, model_type = \"EmbeddingLSTM\"):\n",
    "    model.eval()\n",
    "    words = seed_text.split()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_words):\n",
    "            seq = [word_to_idx.get(word, 0) for word in words[-seq_length:]]\n",
    "            seq = torch.tensor(seq, dtype = torch.long).unsqueeze(0)\n",
    "\n",
    "            if model_type == \"OneHotRNN\":\n",
    "                seq = F.one_hot(seq, num_classes = vocab_size).float()\n",
    "\n",
    "            output = model(seq)\n",
    "            probabilities = F.softmax(output, dim = 1)\n",
    "            predicted_idx = torch.multinomial(probabilities, 1).item()\n",
    "\n",
    "            words.append(idx_to_word[predicted_idx])\n",
    "\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f94b37b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T13:32:16.397855Z",
     "iopub.status.busy": "2025-03-20T13:32:16.397654Z",
     "iopub.status.idle": "2025-03-20T14:14:48.047387Z",
     "shell.execute_reply": "2025-03-20T14:14:48.046506Z"
    },
    "papermill": {
     "duration": 2551.668621,
     "end_time": "2025-03-20T14:14:48.062511",
     "exception": false,
     "start_time": "2025-03-20T13:32:16.393890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotRNN Epoch [1/100], Avg Loss: 7.5763\n",
      "OneHotRNN Epoch [2/100], Avg Loss: 6.7100\n",
      "OneHotRNN Epoch [3/100], Avg Loss: 6.3508\n",
      "OneHotRNN Epoch [4/100], Avg Loss: 6.1623\n",
      "OneHotRNN Epoch [5/100], Avg Loss: 5.9785\n",
      "OneHotRNN Epoch [6/100], Avg Loss: 5.7745\n",
      "OneHotRNN Epoch [7/100], Avg Loss: 5.5463\n",
      "OneHotRNN Epoch [8/100], Avg Loss: 5.3516\n",
      "OneHotRNN Epoch [9/100], Avg Loss: 5.2218\n",
      "OneHotRNN Epoch [10/100], Avg Loss: 5.0151\n",
      "OneHotRNN Epoch [11/100], Avg Loss: 4.8419\n",
      "OneHotRNN Epoch [12/100], Avg Loss: 4.6586\n",
      "OneHotRNN Epoch [13/100], Avg Loss: 4.4254\n",
      "OneHotRNN Epoch [14/100], Avg Loss: 4.1530\n",
      "OneHotRNN Epoch [15/100], Avg Loss: 3.8493\n",
      "OneHotRNN Epoch [16/100], Avg Loss: 3.6265\n",
      "OneHotRNN Epoch [17/100], Avg Loss: 3.4035\n",
      "OneHotRNN Epoch [18/100], Avg Loss: 3.0912\n",
      "OneHotRNN Epoch [19/100], Avg Loss: 2.7623\n",
      "OneHotRNN Epoch [20/100], Avg Loss: 2.4713\n",
      "OneHotRNN Epoch [21/100], Avg Loss: 2.2557\n",
      "OneHotRNN Epoch [22/100], Avg Loss: 2.0474\n",
      "OneHotRNN Epoch [23/100], Avg Loss: 1.7992\n",
      "OneHotRNN Epoch [24/100], Avg Loss: 1.5678\n",
      "OneHotRNN Epoch [25/100], Avg Loss: 1.3588\n",
      "OneHotRNN Epoch [26/100], Avg Loss: 1.1796\n",
      "OneHotRNN Epoch [27/100], Avg Loss: 1.0401\n",
      "OneHotRNN Epoch [28/100], Avg Loss: 0.9147\n",
      "OneHotRNN Epoch [29/100], Avg Loss: 0.7895\n",
      "OneHotRNN Epoch [30/100], Avg Loss: 0.6745\n",
      "OneHotRNN Epoch [31/100], Avg Loss: 0.5742\n",
      "OneHotRNN Epoch [32/100], Avg Loss: 0.4849\n",
      "OneHotRNN Epoch [33/100], Avg Loss: 0.4173\n",
      "OneHotRNN Epoch [34/100], Avg Loss: 0.3602\n",
      "OneHotRNN Epoch [35/100], Avg Loss: 0.3138\n",
      "OneHotRNN Epoch [36/100], Avg Loss: 0.2786\n",
      "OneHotRNN Epoch [37/100], Avg Loss: 0.2475\n",
      "OneHotRNN Epoch [38/100], Avg Loss: 0.2204\n",
      "OneHotRNN Epoch [39/100], Avg Loss: 0.1988\n",
      "OneHotRNN Epoch [40/100], Avg Loss: 0.1757\n",
      "OneHotRNN Epoch [41/100], Avg Loss: 0.1525\n",
      "OneHotRNN Epoch [42/100], Avg Loss: 0.1279\n",
      "OneHotRNN Epoch [43/100], Avg Loss: 0.1099\n",
      "OneHotRNN Epoch [44/100], Avg Loss: 0.0989\n",
      "OneHotRNN Epoch [45/100], Avg Loss: 0.0844\n",
      "OneHotRNN Epoch [46/100], Avg Loss: 0.0864\n",
      "OneHotRNN Epoch [47/100], Avg Loss: 0.0722\n",
      "OneHotRNN Epoch [48/100], Avg Loss: 0.0648\n",
      "OneHotRNN Epoch [49/100], Avg Loss: 0.0585\n",
      "OneHotRNN Epoch [50/100], Avg Loss: 0.0576\n",
      "OneHotRNN Epoch [51/100], Avg Loss: 0.0590\n",
      "OneHotRNN Epoch [52/100], Avg Loss: 0.0558\n",
      "OneHotRNN Epoch [53/100], Avg Loss: 0.0524\n",
      "OneHotRNN Epoch [54/100], Avg Loss: 0.0490\n",
      "OneHotRNN Epoch [55/100], Avg Loss: 0.0439\n",
      "OneHotRNN Epoch [56/100], Avg Loss: 0.0371\n",
      "OneHotRNN Epoch [57/100], Avg Loss: 0.0347\n",
      "OneHotRNN Epoch [58/100], Avg Loss: 0.0377\n",
      "OneHotRNN Epoch [59/100], Avg Loss: 0.0432\n",
      "OneHotRNN Epoch [60/100], Avg Loss: 0.0356\n",
      "OneHotRNN Epoch [61/100], Avg Loss: 0.0357\n",
      "OneHotRNN Epoch [62/100], Avg Loss: 0.0313\n",
      "OneHotRNN Epoch [63/100], Avg Loss: 0.0293\n",
      "OneHotRNN Epoch [64/100], Avg Loss: 0.0254\n",
      "OneHotRNN Epoch [65/100], Avg Loss: 0.0322\n",
      "OneHotRNN Epoch [66/100], Avg Loss: 0.0277\n",
      "OneHotRNN Epoch [67/100], Avg Loss: 0.0265\n",
      "OneHotRNN Epoch [68/100], Avg Loss: 0.0260\n",
      "OneHotRNN Epoch [69/100], Avg Loss: 0.0237\n",
      "OneHotRNN Epoch [70/100], Avg Loss: 0.0192\n",
      "OneHotRNN Epoch [71/100], Avg Loss: 0.0218\n",
      "OneHotRNN Epoch [72/100], Avg Loss: 0.0238\n",
      "OneHotRNN Epoch [73/100], Avg Loss: 0.0229\n",
      "OneHotRNN Epoch [74/100], Avg Loss: 0.0269\n",
      "OneHotRNN Epoch [75/100], Avg Loss: 0.0287\n",
      "OneHotRNN Epoch [76/100], Avg Loss: 0.0163\n",
      "OneHotRNN Epoch [77/100], Avg Loss: 0.0147\n",
      "OneHotRNN Epoch [78/100], Avg Loss: 0.0159\n",
      "OneHotRNN Epoch [79/100], Avg Loss: 0.0291\n",
      "OneHotRNN Epoch [80/100], Avg Loss: 0.0226\n",
      "OneHotRNN Epoch [81/100], Avg Loss: 0.0143\n",
      "OneHotRNN Epoch [82/100], Avg Loss: 0.0167\n",
      "OneHotRNN Epoch [83/100], Avg Loss: 0.0181\n",
      "OneHotRNN Epoch [84/100], Avg Loss: 0.0203\n",
      "OneHotRNN Epoch [85/100], Avg Loss: 0.0158\n",
      "OneHotRNN Epoch [86/100], Avg Loss: 0.0159\n",
      "OneHotRNN Epoch [87/100], Avg Loss: 0.0170\n",
      "OneHotRNN Epoch [88/100], Avg Loss: 0.0193\n",
      "OneHotRNN Epoch [89/100], Avg Loss: 0.0158\n",
      "OneHotRNN Epoch [90/100], Avg Loss: 0.0171\n",
      "OneHotRNN Epoch [91/100], Avg Loss: 0.0112\n",
      "OneHotRNN Epoch [92/100], Avg Loss: 0.0140\n",
      "OneHotRNN Epoch [93/100], Avg Loss: 0.0167\n",
      "OneHotRNN Epoch [94/100], Avg Loss: 0.0179\n",
      "OneHotRNN Epoch [95/100], Avg Loss: 0.0094\n",
      "OneHotRNN Epoch [96/100], Avg Loss: 0.0128\n",
      "OneHotRNN Epoch [97/100], Avg Loss: 0.0203\n",
      "OneHotRNN Epoch [98/100], Avg Loss: 0.0110\n",
      "OneHotRNN Epoch [99/100], Avg Loss: 0.0062\n",
      "OneHotRNN Epoch [100/100], Avg Loss: 0.0108\n",
      "OneHotRNN Training Time: 1674.02s\n",
      "\n",
      "EmbeddingLSTM Epoch [1/100], Avg Loss: 7.5652\n",
      "EmbeddingLSTM Epoch [2/100], Avg Loss: 6.5659\n",
      "EmbeddingLSTM Epoch [3/100], Avg Loss: 6.0104\n",
      "EmbeddingLSTM Epoch [4/100], Avg Loss: 5.5552\n",
      "EmbeddingLSTM Epoch [5/100], Avg Loss: 5.0735\n",
      "EmbeddingLSTM Epoch [6/100], Avg Loss: 4.6540\n",
      "EmbeddingLSTM Epoch [7/100], Avg Loss: 4.1869\n",
      "EmbeddingLSTM Epoch [8/100], Avg Loss: 3.7699\n",
      "EmbeddingLSTM Epoch [9/100], Avg Loss: 3.4178\n",
      "EmbeddingLSTM Epoch [10/100], Avg Loss: 3.0658\n",
      "EmbeddingLSTM Epoch [11/100], Avg Loss: 2.7512\n",
      "EmbeddingLSTM Epoch [12/100], Avg Loss: 2.4253\n",
      "EmbeddingLSTM Epoch [13/100], Avg Loss: 2.0555\n",
      "EmbeddingLSTM Epoch [14/100], Avg Loss: 1.6933\n",
      "EmbeddingLSTM Epoch [15/100], Avg Loss: 1.3891\n",
      "EmbeddingLSTM Epoch [16/100], Avg Loss: 1.1383\n",
      "EmbeddingLSTM Epoch [17/100], Avg Loss: 0.9348\n",
      "EmbeddingLSTM Epoch [18/100], Avg Loss: 0.7616\n",
      "EmbeddingLSTM Epoch [19/100], Avg Loss: 0.6293\n",
      "EmbeddingLSTM Epoch [20/100], Avg Loss: 0.5103\n",
      "EmbeddingLSTM Epoch [21/100], Avg Loss: 0.4231\n",
      "EmbeddingLSTM Epoch [22/100], Avg Loss: 0.3502\n",
      "EmbeddingLSTM Epoch [23/100], Avg Loss: 0.2930\n",
      "EmbeddingLSTM Epoch [24/100], Avg Loss: 0.2502\n",
      "EmbeddingLSTM Epoch [25/100], Avg Loss: 0.2129\n",
      "EmbeddingLSTM Epoch [26/100], Avg Loss: 0.1947\n",
      "EmbeddingLSTM Epoch [27/100], Avg Loss: 0.1766\n",
      "EmbeddingLSTM Epoch [28/100], Avg Loss: 0.1581\n",
      "EmbeddingLSTM Epoch [29/100], Avg Loss: 0.1444\n",
      "EmbeddingLSTM Epoch [30/100], Avg Loss: 0.1375\n",
      "EmbeddingLSTM Epoch [31/100], Avg Loss: 0.1380\n",
      "EmbeddingLSTM Epoch [32/100], Avg Loss: 0.1231\n",
      "EmbeddingLSTM Epoch [33/100], Avg Loss: 0.1170\n",
      "EmbeddingLSTM Epoch [34/100], Avg Loss: 0.1145\n",
      "EmbeddingLSTM Epoch [35/100], Avg Loss: 0.1198\n",
      "EmbeddingLSTM Epoch [36/100], Avg Loss: 0.1170\n",
      "EmbeddingLSTM Epoch [37/100], Avg Loss: 0.1299\n",
      "EmbeddingLSTM Epoch [38/100], Avg Loss: 0.1260\n",
      "EmbeddingLSTM Epoch [39/100], Avg Loss: 0.1277\n",
      "EmbeddingLSTM Epoch [40/100], Avg Loss: 0.1258\n",
      "EmbeddingLSTM Epoch [41/100], Avg Loss: 0.1178\n",
      "EmbeddingLSTM Epoch [42/100], Avg Loss: 0.0941\n",
      "EmbeddingLSTM Epoch [43/100], Avg Loss: 0.0675\n",
      "EmbeddingLSTM Epoch [44/100], Avg Loss: 0.0431\n",
      "EmbeddingLSTM Epoch [45/100], Avg Loss: 0.0288\n",
      "EmbeddingLSTM Epoch [46/100], Avg Loss: 0.0208\n",
      "EmbeddingLSTM Epoch [47/100], Avg Loss: 0.0198\n",
      "EmbeddingLSTM Epoch [48/100], Avg Loss: 0.0336\n",
      "EmbeddingLSTM Epoch [49/100], Avg Loss: 0.0576\n",
      "EmbeddingLSTM Epoch [50/100], Avg Loss: 0.0467\n",
      "EmbeddingLSTM Epoch [51/100], Avg Loss: 0.0291\n",
      "EmbeddingLSTM Epoch [52/100], Avg Loss: 0.0129\n",
      "EmbeddingLSTM Epoch [53/100], Avg Loss: 0.0059\n",
      "EmbeddingLSTM Epoch [54/100], Avg Loss: 0.0039\n",
      "EmbeddingLSTM Epoch [55/100], Avg Loss: 0.0037\n",
      "EmbeddingLSTM Epoch [56/100], Avg Loss: 0.0032\n",
      "EmbeddingLSTM Epoch [57/100], Avg Loss: 0.0027\n",
      "EmbeddingLSTM Epoch [58/100], Avg Loss: 0.1361\n",
      "EmbeddingLSTM Epoch [59/100], Avg Loss: 0.1164\n",
      "EmbeddingLSTM Epoch [60/100], Avg Loss: 0.0306\n",
      "EmbeddingLSTM Epoch [61/100], Avg Loss: 0.0098\n",
      "EmbeddingLSTM Epoch [62/100], Avg Loss: 0.0045\n",
      "EmbeddingLSTM Epoch [63/100], Avg Loss: 0.0028\n",
      "EmbeddingLSTM Epoch [64/100], Avg Loss: 0.0021\n",
      "EmbeddingLSTM Epoch [65/100], Avg Loss: 0.0016\n",
      "EmbeddingLSTM Epoch [66/100], Avg Loss: 0.0012\n",
      "EmbeddingLSTM Epoch [67/100], Avg Loss: 0.0010\n",
      "EmbeddingLSTM Epoch [68/100], Avg Loss: 0.0007\n",
      "EmbeddingLSTM Epoch [69/100], Avg Loss: 0.0006\n",
      "EmbeddingLSTM Epoch [70/100], Avg Loss: 0.0165\n",
      "EmbeddingLSTM Epoch [71/100], Avg Loss: 0.2634\n",
      "EmbeddingLSTM Epoch [72/100], Avg Loss: 0.0640\n",
      "EmbeddingLSTM Epoch [73/100], Avg Loss: 0.0140\n",
      "EmbeddingLSTM Epoch [74/100], Avg Loss: 0.0051\n",
      "EmbeddingLSTM Epoch [75/100], Avg Loss: 0.0032\n",
      "EmbeddingLSTM Epoch [76/100], Avg Loss: 0.0024\n",
      "EmbeddingLSTM Epoch [77/100], Avg Loss: 0.0018\n",
      "EmbeddingLSTM Epoch [78/100], Avg Loss: 0.0014\n",
      "EmbeddingLSTM Epoch [79/100], Avg Loss: 0.0011\n",
      "EmbeddingLSTM Epoch [80/100], Avg Loss: 0.0008\n",
      "EmbeddingLSTM Epoch [81/100], Avg Loss: 0.0006\n",
      "EmbeddingLSTM Epoch [82/100], Avg Loss: 0.0005\n",
      "EmbeddingLSTM Epoch [83/100], Avg Loss: 0.0004\n",
      "EmbeddingLSTM Epoch [84/100], Avg Loss: 0.0003\n",
      "EmbeddingLSTM Epoch [85/100], Avg Loss: 0.0002\n",
      "EmbeddingLSTM Epoch [86/100], Avg Loss: 0.0002\n",
      "EmbeddingLSTM Epoch [87/100], Avg Loss: 0.2110\n",
      "EmbeddingLSTM Epoch [88/100], Avg Loss: 0.1179\n",
      "EmbeddingLSTM Epoch [89/100], Avg Loss: 0.0215\n",
      "EmbeddingLSTM Epoch [90/100], Avg Loss: 0.0058\n",
      "EmbeddingLSTM Epoch [91/100], Avg Loss: 0.0030\n",
      "EmbeddingLSTM Epoch [92/100], Avg Loss: 0.0021\n",
      "EmbeddingLSTM Epoch [93/100], Avg Loss: 0.0016\n",
      "EmbeddingLSTM Epoch [94/100], Avg Loss: 0.0012\n",
      "EmbeddingLSTM Epoch [95/100], Avg Loss: 0.0010\n",
      "EmbeddingLSTM Epoch [96/100], Avg Loss: 0.0007\n",
      "EmbeddingLSTM Epoch [97/100], Avg Loss: 0.0006\n",
      "EmbeddingLSTM Epoch [98/100], Avg Loss: 0.0004\n",
      "EmbeddingLSTM Epoch [99/100], Avg Loss: 0.0003\n",
      "EmbeddingLSTM Epoch [100/100], Avg Loss: 0.0003\n",
      "EmbeddingLSTM Training Time: 877.62s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Models\n",
    "train_model(onehot_model, onehot_optimizer, \"OneHotRNN\")\n",
    "train_model(embedding_model, embedding_optimizer, \"EmbeddingLSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fa4ca63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T14:14:48.086962Z",
     "iopub.status.busy": "2025-03-20T14:14:48.086661Z",
     "iopub.status.idle": "2025-03-20T14:14:48.213393Z",
     "shell.execute_reply": "2025-03-20T14:14:48.212434Z"
    },
    "papermill": {
     "duration": 0.140741,
     "end_time": "2025-03-20T14:14:48.214860",
     "exception": false,
     "start_time": "2025-03-20T14:14:48.074119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Poem (OneHotRNN): I wandered lonely as a great had left behind a heart life shot, can laugh and free late? The pilot desert the child that by the women, sings of the country fast, And now we shall I’d To sing me all my only ride The ring beside the touch And now We with me beneath\n",
      "\n",
      "Generated Poem (EmbeddingLSTM): I wandered lonely as a trifle, they are not the small returns to the inner were ever the to that sun, I can do nothing and my red them. And what are you? this all that is not by the great tomb of man. The golden sun, The planets, all the infinite host of heaven,\n"
     ]
    }
   ],
   "source": [
    "# Generate Poems\n",
    "seed_text = \"I wandered lonely as a\"\n",
    "print(\"\\nGenerated Poem (OneHotRNN):\", generate_poem(onehot_model, seed_text, model_type = \"OneHotRNN\"))\n",
    "print(\"\\nGenerated Poem (EmbeddingLSTM):\", generate_poem(embedding_model, seed_text, model_type = \"EmbeddingLSTM\"))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6623322,
     "sourceId": 10689716,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2562.333076,
   "end_time": "2025-03-20T14:14:49.553438",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-20T13:32:07.220362",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
